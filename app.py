"""
Streamlit demo app for the Two-Stage Sound Event Detection (SED) and alert system.

This is a lightweight interactive front end aligned with the architecture in Arch.png:
PyAudio/ffmpeg (source) -> Librosa (pre-processing) -> Stage-1 CNN (edge) ->
Redis buffer (not used here) -> Transformer/CRNN (sequence refine) -> UI alerts.

The app uses a synthetic detector for demonstration; integrate your real Torch
models by replacing Stage1CNNEdgeDetector and Stage2SequenceRefiner.
"""

from __future__ import annotations

import io
import math
import uuid
from dataclasses import dataclass
from typing import Iterable, List, Tuple

import librosa
import matplotlib.pyplot as plt
import numpy as np
import soundfile as sf
import streamlit as st


# --------- Data structures ----------------------------------------------------

@dataclass
class DetectionEvent:
    start: float
    end: float
    label: str
    score: float
    stage: str


# --------- Demo pipeline components ------------------------------------------

class Stage1CNNEdgeDetector:
    """
    Placeholder for the lightweight CNN edge detector.
    Uses energy + spectral centroid heuristics to mimic coarse detection.
    """

    def __init__(self, sample_rate: int, threshold: float):
        self.sample_rate = sample_rate
        self.threshold = threshold

    def predict(self, y: np.ndarray, frame_length: int, hop_length: int) -> List[DetectionEvent]:
        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
        centroid = librosa.feature.spectral_centroid(
            y=y, sr=self.sample_rate, hop_length=hop_length
        )[0]
        rms_norm = (rms - rms.min()) / (rms.max() - rms.min() + 1e-8)
        cent_norm = (centroid - centroid.min()) / (centroid.max() - centroid.min() + 1e-8)
        energy_score = 0.6 * rms_norm + 0.4 * cent_norm

        frame_times = librosa.frames_to_time(
            np.arange(len(rms)), sr=self.sample_rate, hop_length=hop_length
        )
        events: List[DetectionEvent] = []
        active = energy_score > self.threshold
        start_idx = None
        for idx, is_active in enumerate(active):
            if is_active and start_idx is None:
                start_idx = idx
            if not is_active and start_idx is not None:
                end_idx = idx
                events.append(
                    DetectionEvent(
                        start=float(frame_times[start_idx]),
                        end=float(frame_times[end_idx]),
                        label="candidate",
                        score=float(energy_score[start_idx:end_idx].max()),
                        stage="stage1",
                    )
                )
                start_idx = None
        if start_idx is not None:
            events.append(
                DetectionEvent(
                    start=float(frame_times[start_idx]),
                    end=float(frame_times[-1]),
                    label="candidate",
                    score=float(energy_score[start_idx:].max()),
                    stage="stage1",
                )
            )
        return events


class Stage2SequenceRefiner:
    """
    Placeholder for Transformer/CRNN sequence refinement.
    Applies smoothing and re-labeling to mimic temporal consistency.
    """

    def __init__(self, class_map: Iterable[str], min_duration: float, bonus: float):
        self.class_map = list(class_map)
        self.min_duration = min_duration
        self.bonus = bonus

    def refine(self, events: List[DetectionEvent]) -> List[DetectionEvent]:
        refined: List[DetectionEvent] = []
        for ev in events:
            duration = ev.end - ev.start
            if duration < self.min_duration:
                ev.end = ev.start + self.min_duration
            label_idx = int(math.floor(ev.score * len(self.class_map))) % len(self.class_map)
            label = self.class_map[label_idx]
            score = min(1.0, ev.score + self.bonus)
            refined.append(
                DetectionEvent(
                    start=ev.start,
                    end=ev.end,
                    label=label,
                    score=score,
                    stage="stage2",
                )
            )
        return refined


# --------- Helpers ------------------------------------------------------------

def load_audio(file: io.BytesIO, sample_rate: int) -> Tuple[np.ndarray, int]:
    y, sr = librosa.load(file, sr=sample_rate, mono=True)
    return y, sr


def generate_demo_audio(duration: float = 8.0, sample_rate: int = 16000) -> Tuple[np.ndarray, int]:
    rng = np.random.default_rng(0xC0DE)
    t = np.linspace(0, duration, int(sample_rate * duration), endpoint=False)
    noise = rng.normal(0, 0.02, size=t.shape)

    gunshot_center = int(0.35 * len(t))
    gunshot = np.zeros_like(t)
    gunshot[gunshot_center : gunshot_center + 300] = 1.0
    gunshot = np.convolve(gunshot, np.hanning(120), mode="same")

    glass_center = int(0.72 * len(t))
    glass = np.zeros_like(t)
    glass[glass_center : glass_center + 600] = np.sin(2 * np.pi * 5500 * t[:600]) * np.hanning(600)

    y = noise + 0.8 * gunshot + 0.4 * glass
    y = y / np.abs(y).max()
    return y.astype(np.float32), sample_rate


def plot_spectrogram(y: np.ndarray, sr: int) -> plt.Figure:
    fig, ax = plt.subplots(figsize=(8, 3))
    spec = librosa.power_to_db(librosa.feature.melspectrogram(y=y, sr=sr, n_mels=64), ref=np.max)
    img = librosa.display.specshow(spec, sr=sr, x_axis="time", y_axis="mel", ax=ax)
    fig.colorbar(img, ax=ax, format="%+2.0f dB")
    ax.set_title("Log-Mel Spectrogram")
    fig.tight_layout()
    return fig


def format_events(events: List[DetectionEvent]) -> List[dict]:
    return [
        {
            "Start (s)": round(ev.start, 2),
            "End (s)": round(ev.end, 2),
            "Label": ev.label,
            "Score": round(ev.score, 3),
            "Stage": ev.stage,
        }
        for ev in events
    ]


# --------- Streamlit UI -------------------------------------------------------

def main() -> None:
    st.set_page_config(
        page_title="GUARD | Urban Acoustic SED & Alert Demo",
        page_icon="ğŸ§",
        layout="wide",
    )
    st.title("GUARDï¼šåŸå¸‚è²éŸ³äº‹ä»¶åµæ¸¬èˆ‡å…¬å…±å®‰å…¨è­¦å ± â€” äº’å‹• Demo")
    st.markdown("**Sloganï¼šGUARD: The City Never Sleeps, Neither Do We.**")
    st.caption("General Urban Audio Recognition & Defense â€” å®ˆè­·èˆ‡é˜²ç¦¦ï¼Œå¼·èª¿ç³»çµ±å®‰å…¨æ€§èˆ‡å¯é æ€§ã€‚")
    st.caption("Two-Stage SED (CNN â†’ Transformer/CRNN) with Librosa preprocessing. "
               "Uploadæˆ–ä½¿ç”¨åˆæˆç¯„ä¾‹éŸ³è¨Šï¼Œèª¿æ•´é–¾å€¼èˆ‡æ™‚åºè¨­å®šï¼ŒæŸ¥çœ‹åµæ¸¬çµæœã€‚")

    with st.sidebar:
        st.header("âš™ï¸ æ¨è«–è¨­å®š")
        sr = st.number_input("Sample rate", value=16000, step=1000, min_value=8000, max_value=48000)
        frame_len_sec = st.slider("Frame length (seconds)", 0.5, 2.5, 1.0, 0.25)
        hop_len_sec = st.slider("Hop length (seconds)", 0.1, 1.0, 0.25, 0.05)
        stage1_threshold = st.slider("Stage-1 energy threshold", 0.05, 0.9, 0.35, 0.01)
        stage2_bonus = st.slider("Stage-2 score bonus", 0.0, 0.5, 0.1, 0.01)
        min_duration = st.slider("Stage-2 min duration (s)", 0.1, 2.0, 0.4, 0.1)
        class_map = st.multiselect(
            "äº‹ä»¶é¡åˆ¥æ˜ å°„ (ç¤ºæ„)",
            options=["gunshot", "glass_break", "car_horn", "scream", "other"],
            default=["gunshot", "glass_break", "scream"],
        )
        st.divider()
        st.markdown("**äº’å‹•å…ƒç´ **")
        show_spectrogram = st.checkbox("é¡¯ç¤ºé »è­œåœ–", value=True)
        allow_download = st.checkbox("å…è¨±ä¸‹è¼‰åµæ¸¬çµæœ CSV", value=True)

    st.subheader("1) è¼‰å…¥éŸ³è¨Š")
    uploaded = st.file_uploader("ä¸Šå‚³ WAV/OGG/FLAC/MP3", type=["wav", "ogg", "flac", "mp3"])
    use_demo = st.checkbox("ä½¿ç”¨å…§å»ºåˆæˆç¯„ä¾‹éŸ³è¨Šï¼ˆå«æ§éŸ¿+ç»ç’ƒç ´è£‚ï¼‰", value=uploaded is None)
    audio_bytes: bytes | None = None
    audio_np: np.ndarray | None = None

    if uploaded is not None:
        audio_bytes = uploaded.read()
        audio_np, sr = load_audio(io.BytesIO(audio_bytes), sample_rate=sr)
    elif use_demo:
        audio_np, sr = generate_demo_audio(sample_rate=sr)
        buffer = io.BytesIO()
        sf.write(buffer, audio_np, sr, format="WAV")
        audio_bytes = buffer.getvalue()

    if audio_bytes:
        st.audio(audio_bytes, format="audio/wav")

    if audio_np is None:
        st.info("è«‹ä¸Šå‚³éŸ³è¨Šæˆ–å•Ÿç”¨åˆæˆç¯„ä¾‹ã€‚")
        return

    st.subheader("2) ç‰¹å¾µèˆ‡å…©éšæ®µæ¨è«–")
    frame_length = int(frame_len_sec * sr)
    hop_length = int(hop_len_sec * sr)

    stage1 = Stage1CNNEdgeDetector(sample_rate=sr, threshold=stage1_threshold)
    stage2 = Stage2SequenceRefiner(class_map=class_map or ["other"], min_duration=min_duration, bonus=stage2_bonus)

    with st.spinner("é‹è¡Œåµæ¸¬ä¸­â€¦"):
        stage1_events = stage1.predict(audio_np, frame_length=frame_length, hop_length=hop_length)
        refined_events = stage2.refine(stage1_events)

    col1, col2 = st.columns([2, 1])
    with col1:
        st.markdown("**éšæ®µ 1ï¼šCNN é‚Šç·£åµæ¸¬ (ç¤ºæ„)**")
        st.dataframe(format_events(stage1_events), use_container_width=True, hide_index=True)
    with col2:
        st.markdown("**éšæ®µ 2ï¼šTransformer/CRNN æ™‚åºç²¾ç…‰ (ç¤ºæ„)**")
        st.dataframe(format_events(refined_events), use_container_width=True, hide_index=True)

    if allow_download and refined_events:
        csv_buffer = io.StringIO()
        csv_buffer.write("id,start,end,label,score,stage\n")
        for ev in refined_events:
            csv_buffer.write(
                f"{uuid.uuid4().hex},{ev.start:.3f},{ev.end:.3f},{ev.label},{ev.score:.3f},{ev.stage}\n"
            )
        st.download_button(
            "ä¸‹è¼‰åµæ¸¬çµæœ CSV",
            data=csv_buffer.getvalue().encode("utf-8"),
            file_name="sed_events.csv",
            mime="text/csv",
        )

    st.subheader("3) éŸ³è¨Šè¦–è¦ºåŒ–")
    if show_spectrogram:
        fig = plot_spectrogram(audio_np, sr)
        st.pyplot(fig, clear_figure=True, use_container_width=True)

    st.subheader("4) å¦‚ä½•æ›æˆçœŸå¯¦æ¨¡å‹ï¼Ÿ")
    st.markdown(
        """
- ä»¥ TorchScript æˆ– ONNX è¼‰å…¥ä½ çš„ Stage-1 CNNï¼Œå°‡ `Stage1CNNEdgeDetector.predict` æ”¹ç‚ºæ¨¡å‹æ¨è«–ã€‚
- å°‡ Stage-2 æ›æˆå·²è¨“ç·´çš„ Transformer/CRNNï¼Œè¼¸å…¥åºåˆ—ç‰¹å¾µæˆ– logitsï¼Œè¼¸å‡ºäº‹ä»¶åˆ—è¡¨ã€‚
- è‹¥éœ€ Redis ç·©è¡ï¼Œå¾ Stage-1 ç”¢ç”Ÿçš„ logits/ç‰¹å¾µæ¨å…¥ç·©è¡ï¼Œå†ç”± Stage-2 æ‰¹æ¬¡è®€å–ã€‚
- å°‡å‘Šè­¦ç®¡é“ï¼ˆWebhook/SMS/Emailï¼‰æ¥åœ¨ Stage-2 çµæœä¸Šï¼Œä¾æ“šé–¾å€¼èˆ‡å†·å»æ™‚é–“æ¨é€ã€‚
"""
    )


if __name__ == "__main__":
    main()
